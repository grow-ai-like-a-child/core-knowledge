# Core Knowledge Deficits in Multi-Modal Language Models

**Official website for the ICML 2025 paper submission**

ğŸŒ **Website**: [https://williamium3000.github.io/core-knowledge](https://williamium3000.github.io/core-knowledge)  
ğŸ“„ **Paper**: [https://arxiv.org/abs/2410.10855](https://arxiv.org/abs/2410.10855)  
ğŸ¤— **Dataset**: [https://huggingface.co/grow-ai-like-a-child](https://huggingface.co/grow-ai-like-a-child)

## ğŸ“– About

This repository contains the official website for our paper "Core Knowledge Deficits in Multi-Modal Language Models". The website presents our comprehensive evaluation of 230 multi-modal language models using the **CoreCognition** benchmark, which assesses 12 foundational cognitive concepts grounded in developmental cognitive science.

## ğŸ” Key Findings

Our research reveals four critical shortcomings in state-of-the-art Multi-modal Large Language Models (MLLMs):

1. **Core Knowledge Deficits**: MLLMs excel at higher-level abilities but struggle with lower-level cognitive abilities
2. **Misaligned Dependency**: Core abilities show weak cross-stage correlations, lacking developmental scaffolding
3. **Predictability**: Performance on core knowledge predicts higher-level abilities
4. **Limited Scaling**: MLLMs show minimal scalability improvements on low-level abilities compared to high-level ones

## ğŸ§  CoreCognition Benchmark

The **CoreCognition** benchmark evaluates twelve foundational cognitive concepts:

1. **Permanence** - Objects persist when not perceived
2. **Continuity** - Objects remain unified across space and time
3. **Boundary** - Transitions between objects
4. **Spatiality** - Understanding Euclidean properties
5. **Perceptual Constancy** - Appearance changes â‰  property changes
6. **Intuitive Physics** - Laws of physical interaction
7. **Perspective** - Seeing what others see
8. **Hierarchy** - Inclusion/exclusion of objects and categories
9. **Conservation** - Property invariances despite transformations
10. **Tool Use** - Manipulating objects to achieve goals
11. **Intentionality** - Understanding what others want
12. **Mechanical Reasoning** - Inferring actions from system states

## ğŸ”¬ Concept Hacking

We introduce **Concept Hacking**, a novel controlled evaluation method that systematically manipulates task-relevant features while preserving task-irrelevant conditions. This reveals that MLLMs fail to develop genuine core knowledge understanding and instead rely on shortcut learning as they scale.

## ğŸ“Š Evaluation Scale

- **230 MLLMs** evaluated across different model families and sizes
- **11 different prompts** to ensure robust evaluation
- **>26,000 total judgments** across all models and tasks
- **2,530 image-question pairs** in the benchmark

## ğŸ—ï¸ Website Structure

```
â”œâ”€â”€ _config.yml              # Jekyll configuration
â”œâ”€â”€ _layouts/
â”‚   â””â”€â”€ default.html         # Main layout template
â”œâ”€â”€ index.html               # Homepage with full paper content
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/              # Paper figures and illustrations
â”‚   â”œâ”€â”€ growai.png          # Site favicon
â”‚   â””â”€â”€ favicon.svg         # Backup favicon
â”œâ”€â”€ Gemfile                  # Ruby dependencies
â””â”€â”€ README.md               # This file
```

## ğŸš€ Local Development

To run the website locally:

```bash
# Install dependencies
gem install jekyll bundler
bundle install

# Serve the site locally
bundle exec jekyll serve --livereload
```

Then visit: `http://localhost:4000/core-knowledge`

## ğŸ‘¥ Authors

**Yijiang LiÂ¹**, **Qingying GaoÂ²,Â§**, **Tianwei ZhaoÂ²,Â§**, **Bingyang WangÂ³,Â§**, **Haoran SunÂ²**, **Haiyun Lyuâ´**, **Robert D. Hawkinsâµ**, **Nuno VasconcelosÂ¹**, **Tal Golanâ¶**, **Dezhi Luoâ·,â¸,â€ **, **Hokin Dengâ¹,â€ **

Â¹University of California San Diego, Â²Johns Hopkins University, Â³Emory University, â´University of North Carolina at Chapel Hill, âµStanford University, â¶Ben-Gurion University of the Negev, â·University of Michigan, â¸University College London, â¹Carnegie Mellon University

Â§Equal Contribution, â€ Corresponding author

## ğŸ“„ Citation

If you find this work useful in your research, please consider citing:

```bibtex
@article{li2025core,
    title={Core Knowledge Deficits in Multi-Modal Language Models}, 
    author={Li, Yijiang and Gao, Qingying and Zhao, Tianwei and Wang, Bingyang and Sun, Haoran and Lyu, Haiyun and Luo, Dezhi and Deng, Hokin},
    journal={arXiv preprint arXiv:2410.10855},
    year={2025}
}
```

## ğŸ“§ Contact

For questions about the paper or dataset, please contact the corresponding authors:
- Dezhi Luo: [dezhi@umich.edu](mailto:dezhi@umich.edu)
- Hokin Deng: [hokindeng@cmu.edu](mailto:hokindeng@cmu.edu)

## ğŸ”§ Technical Details

The website is built with:
- **Jekyll** for static site generation
- **Tailwind CSS** for styling
- **GitHub Pages** for hosting
- **Responsive design** optimized for all devices
- **SEO optimization** for better discoverability

---

*This website presents the official results and findings from our comprehensive evaluation of multi-modal language models on core cognitive abilities.*
